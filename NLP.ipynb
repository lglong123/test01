{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOVeVfnIRqSvzVFL5AwD2zb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lglong123/test01/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GCJVlZ7PTb9"
      },
      "source": [
        "#链接谷歌云盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#进入谷歌硬盘\n",
        "%cd ./gdrive/MyDrive/\n",
        "#显卡信息\n",
        "!nvidia-smi\n",
        "#安装依赖\n",
        "!pip3 install -r requirements.txt\n",
        "#生成依赖\n",
        "!pip3 freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCAwoNGG3e2j"
      },
      "source": [
        "#引用 requests文件\n",
        "import requests\n",
        "#下载地址\n",
        "Download_addres='https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin'\n",
        "#把下载地址发送给requests模块\n",
        "f=requests.get(Download_addres)\n",
        "#下载文件\n",
        "with open(\"/content/gdrive/MyDrive/Bert-Multi-Label-Text-Classification/pybert/pretrain/bert/base-uncased/pytorch_model.bin\",\"wb\") as code:\n",
        "     code.write(f.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sQgnh-WLHgg"
      },
      "source": [
        "!git clone https://github.com/hellonlp/classifier_multi_label_textcnn.git\n",
        "#kaggle数据\n",
        "!git clone https://github.com/wshuyi/demo-multi-label-classification-bert.git\n",
        "#!git clone https://github.com/percent4/keras_bert_multi_label_cls.git\n",
        "#本例项目\n",
        "!git clone https://github.com/lonePatient/Bert-Multi-Label-Text-Classification.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9njVwkGcwwHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4260a0c7-f4c6-49bb-cf0e-1f146ecfce10"
      },
      "source": [
        "%cd ./gdrive/MyDrive/Bert-Multi-Label-Text-Classification/\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Bert-Multi-Label-Text-Classification\n",
            "Bert-Multi-Label-Text-Classification  Pipfile\t      requirements.txt\n",
            "classifier_multi_label_textcnn\t      predict_one.py  run_albert.py\n",
            "__init__.py\t\t\t      pybert\t      run_bert.py\n",
            "LICENSE\t\t\t\t      README.md       run_xlnet.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHRTst9E8ojQ",
        "outputId": "b91f6352-ecf5-4bb2-9e65-98d23f2849f8"
      },
      "source": [
        "###在项目目录下运行\n",
        "#1. preprocess data.\n",
        "!python run_bert.py --do_data\n",
        "#--do_train --save_best --do_lower_case"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-07 11:47:11.239337: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/07/2021 11:47:12 - INFO - root -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, arch='bert', data_name='kaggle', do_data=True, do_lower_case=False, do_test=False, do_train=False, epochs=6, eval_batch_size=8, eval_max_seq_len=256, fp16=False, fp16_opt_level='O1', grad_clip=1.0, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, loss_scale=0, mode='min', monitor='valid_loss', n_gpu='0', predict_checkpoints=0, resume_path='', save_best=False, seed=42, sorted=1, train_batch_size=8, train_max_seq_len=256, valid_size=0.2, warmup_proportion=0.1, weight_decay=0.01)\n",
            "06/07/2021 11:47:14 - INFO - root -   split raw data into train and valid\n",
            "[bucket] 10871/10871 [==============================] 52.1us/step"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMJeY5rhUblw",
        "outputId": "9fc0f44b-cc99-4f73-f3f7-f24d82a1faca"
      },
      "source": [
        "###在项目目录下运行\n",
        "#2. fine tuning bert model.\n",
        "!python run_bert.py --do_train --save_best --do_lower_case"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-09 15:22:27.234976: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/09/2021 15:22:28 - INFO - root -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, arch='bert', data_name='kaggle', do_data=False, do_lower_case=True, do_test=False, do_train=True, epochs=6, eval_batch_size=32, eval_max_seq_len=256, fp16=False, fp16_opt_level='O1', grad_clip=1.0, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, loss_scale=0, mode='min', monitor='valid_loss', n_gpu='0', predict_checkpoints=0, resume_path='', save_best=True, seed=42, sorted=1, train_batch_size=32, train_max_seq_len=256, valid_size=0.2, warmup_proportion=0.1, weight_decay=0.01)\n",
            "['CONFIDENTIALITY', 'INTEGRITY', 'OTHER', 'AVAILABILITY', 'ACCOUNTABILITY', 'PRIVACY']\n",
            "{'CONFIDENTIALITY': 0, 'INTEGRITY': 1, 'OTHER': 2, 'AVAILABILITY': 3, 'ACCOUNTABILITY': 4, 'PRIVACY': 5}\n",
            "{0: 'CONFIDENTIALITY', 1: 'INTEGRITY', 2: 'OTHER', 3: 'AVAILABILITY', 4: 'ACCOUNTABILITY', 5: 'PRIVACY'}\n",
            "06/09/2021 15:22:29 - INFO - root -     Num train = 8697\n",
            "06/09/2021 15:22:29 - INFO - root -   Loading examples from cached file pybert/dataset/cached_train_examples_bert\n",
            "06/09/2021 15:22:29 - INFO - root -     Num train_examples = 8697\n",
            "06/09/2021 15:22:29 - INFO - root -   Loading features from cached file pybert/dataset/cached_train_features_256_bert\n",
            "06/09/2021 15:22:29 - INFO - root -   sorted data by th length of input\n",
            "06/09/2021 15:22:29 - INFO - root -   Loading examples from cached file pybert/dataset/cached_valid_examples_bert\n",
            "06/09/2021 15:22:29 - INFO - root -   Loading features from cached file pybert/dataset/cached_valid_features_256_bert\n",
            "06/09/2021 15:22:29 - INFO - root -   initializing model\n",
            "06/09/2021 15:22:29 - INFO - transformers.configuration_utils -   loading configuration file pybert/pretrain/bert/base-uncased/config.json\n",
            "06/09/2021 15:22:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 6,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "06/09/2021 15:22:29 - INFO - transformers.modeling_utils -   loading weights file pybert/pretrain/bert/base-uncased/pytorch_model.bin\n",
            "06/09/2021 15:22:33 - INFO - transformers.modeling_utils -   Weights of BertForMultiLable not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "06/09/2021 15:22:33 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMultiLable: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "06/09/2021 15:22:33 - INFO - root -   initializing callbacks\n",
            "06/09/2021 15:22:33 - INFO - root -   ***** Running training *****\n",
            "06/09/2021 15:22:33 - INFO - root -     Num examples = 8697\n",
            "06/09/2021 15:22:33 - INFO - root -     Num Epochs = 6\n",
            "06/09/2021 15:22:33 - INFO - root -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "06/09/2021 15:22:33 - INFO - root -     Gradient Accumulation steps = 1\n",
            "06/09/2021 15:22:33 - INFO - root -     Total optimization steps = 1632\n",
            "06/09/2021 15:22:36 - INFO - root -   Epoch 1/6\n",
            "[Training] 272/272 [==============================] 215.9ms/step  accuracy: 1.0000 - loss: 0.0239 \n",
            "------------- train result --------------\n",
            "label:CONFIDENTIALITY - auc: 0.8495\n",
            "label:INTEGRITY - auc: 0.8414\n",
            "label:OTHER - auc: 0.8414\n",
            "label:AVAILABILITY - auc: 0.6427\n",
            "label:ACCOUNTABILITY - auc: 0.8776\n",
            "label:PRIVACY - auc: 0.7729\n",
            "[Evaluating] 68/68 [==============================] 160.1ms/step------------- valid result --------------\n",
            "label:CONFIDENTIALITY - auc: 0.9088\n",
            "label:INTEGRITY - auc: 0.9195\n",
            "label:OTHER - auc: 0.8954\n",
            "label:AVAILABILITY - auc: 0.3257\n",
            "label:ACCOUNTABILITY - auc: 0.9464\n",
            "label:PRIVACY - auc: 0.3873\n",
            "06/09/2021 15:23:45 - INFO - root -   \n",
            "Epoch: 1 -  loss: 0.3631 - auc: 0.8839 - valid_loss: 0.3727 - valid_auc: 0.9189 \n",
            "06/09/2021 15:23:45 - INFO - root -   \n",
            "Epoch 1: valid_loss improved from inf to 0.37273\n",
            "06/09/2021 15:23:45 - INFO - transformers.configuration_utils -   Configuration saved in pybert/output/checkpoints/bert/config.json\n",
            "06/09/2021 15:23:47 - INFO - transformers.modeling_utils -   Model weights saved in pybert/output/checkpoints/bert/pytorch_model.bin\n",
            "06/09/2021 15:23:48 - INFO - root -   Epoch 2/6\n",
            "[Training] 272/272 [==============================] 213.0ms/step  accuracy: 1.0000 - loss: 0.0133 \n",
            "------------- train result --------------\n",
            "label:CONFIDENTIALITY - auc: 0.9187\n",
            "label:INTEGRITY - auc: 0.9213\n",
            "label:OTHER - auc: 0.9139\n",
            "label:AVAILABILITY - auc: 0.6319\n",
            "label:ACCOUNTABILITY - auc: 0.9584\n",
            "label:PRIVACY - auc: 0.7730\n",
            "[Evaluating] 68/68 [==============================] 164.3ms/step------------- valid result --------------\n",
            "label:CONFIDENTIALITY - auc: 0.9326\n",
            "label:INTEGRITY - auc: 0.9320\n",
            "label:OTHER - auc: 0.9299\n",
            "label:AVAILABILITY - auc: 0.4828\n",
            "label:ACCOUNTABILITY - auc: 0.9611\n",
            "label:PRIVACY - auc: 0.7509\n",
            "06/09/2021 15:24:57 - INFO - root -   \n",
            "Epoch: 2 -  loss: 0.2370 - auc: 0.9463 - valid_loss: 0.2517 - valid_auc: 0.9479 \n",
            "06/09/2021 15:24:57 - INFO - root -   \n",
            "Epoch 2: valid_loss improved from 0.37273 to 0.25166\n",
            "06/09/2021 15:24:57 - INFO - transformers.configuration_utils -   Configuration saved in pybert/output/checkpoints/bert/config.json\n",
            "06/09/2021 15:24:59 - INFO - transformers.modeling_utils -   Model weights saved in pybert/output/checkpoints/bert/pytorch_model.bin\n",
            "06/09/2021 15:24:59 - INFO - root -   Epoch 3/6\n",
            "[Training] 272/272 [==============================] 213.3ms/step  accuracy: 1.0000 - loss: 0.0097 \n",
            "------------- train result --------------\n",
            "label:CONFIDENTIALITY - auc: 0.9517\n",
            "label:INTEGRITY - auc: 0.9466\n",
            "label:OTHER - auc: 0.9459\n",
            "label:AVAILABILITY - auc: 0.7091\n",
            "label:ACCOUNTABILITY - auc: 0.9806\n",
            "label:PRIVACY - auc: 0.8808\n",
            "[Evaluating] 68/68 [==============================] 162.8ms/step------------- valid result --------------\n",
            "label:CONFIDENTIALITY - auc: 0.9438\n",
            "label:INTEGRITY - auc: 0.9400\n",
            "label:OTHER - auc: 0.9417\n",
            "label:AVAILABILITY - auc: 0.6479\n",
            "label:ACCOUNTABILITY - auc: 0.9668\n",
            "label:PRIVACY - auc: 0.8613\n",
            "06/09/2021 15:26:08 - INFO - root -   \n",
            "Epoch: 3 -  loss: 0.1872 - auc: 0.9675 - valid_loss: 0.2155 - valid_auc: 0.9577 \n",
            "06/09/2021 15:26:09 - INFO - root -   \n",
            "Epoch 3: valid_loss improved from 0.25166 to 0.21546\n",
            "06/09/2021 15:26:09 - INFO - transformers.configuration_utils -   Configuration saved in pybert/output/checkpoints/bert/config.json\n",
            "06/09/2021 15:26:10 - INFO - transformers.modeling_utils -   Model weights saved in pybert/output/checkpoints/bert/pytorch_model.bin\n",
            "06/09/2021 15:26:10 - INFO - root -   Epoch 4/6\n",
            "[Training] 272/272 [==============================] 214.7ms/step  accuracy: 1.0000 - loss: 0.0084 \n",
            "------------- train result --------------\n",
            "label:CONFIDENTIALITY - auc: 0.9665\n",
            "label:INTEGRITY - auc: 0.9601\n",
            "label:OTHER - auc: 0.9650\n",
            "label:AVAILABILITY - auc: 0.7814\n",
            "label:ACCOUNTABILITY - auc: 0.9883\n",
            "label:PRIVACY - auc: 0.9321\n",
            "[Evaluating] 68/68 [==============================] 161.9ms/step------------- valid result --------------\n",
            "label:CONFIDENTIALITY - auc: 0.9461\n",
            "label:INTEGRITY - auc: 0.9442\n",
            "label:OTHER - auc: 0.9475\n",
            "label:AVAILABILITY - auc: 0.7301\n",
            "label:ACCOUNTABILITY - auc: 0.9681\n",
            "label:PRIVACY - auc: 0.9062\n",
            "06/09/2021 15:27:20 - INFO - root -   \n",
            "Epoch: 4 -  loss: 0.1571 - auc: 0.9773 - valid_loss: 0.2089 - valid_auc: 0.9605 \n",
            "06/09/2021 15:27:20 - INFO - root -   \n",
            "Epoch 4: valid_loss improved from 0.21546 to 0.20889\n",
            "06/09/2021 15:27:20 - INFO - transformers.configuration_utils -   Configuration saved in pybert/output/checkpoints/bert/config.json\n",
            "06/09/2021 15:27:21 - INFO - transformers.modeling_utils -   Model weights saved in pybert/output/checkpoints/bert/pytorch_model.bin\n",
            "06/09/2021 15:27:21 - INFO - root -   Epoch 5/6\n",
            "[Training] 272/272 [==============================] 214.3ms/step  accuracy: 1.0000 - loss: 0.0070 \n",
            "------------- train result --------------\n",
            "label:CONFIDENTIALITY - auc: 0.9749\n",
            "label:INTEGRITY - auc: 0.9709\n",
            "label:OTHER - auc: 0.9749\n",
            "label:AVAILABILITY - auc: 0.8496\n",
            "label:ACCOUNTABILITY - auc: 0.9916\n",
            "label:PRIVACY - auc: 0.9547\n",
            "[Evaluating] 52/68 [=====================>........] - ETA: 2s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dA1TQyRYS7k"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I05w0cFA7iDQ"
      },
      "source": [
        "###在项目目录下运行\n",
        "#3. predict new data.\n",
        "!python run_bert.py --do_test --do_lower_case"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}